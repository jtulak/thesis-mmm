
\chapter{XFS filesystem} \label{chap:xfs}

XFS is a journaling filesystem created by SGI in 1993. The new filesystem, intended as a powerful replacement of EFS with the expectation of growing amount of data in the future was first released in IRIX 5.3. Linux port began in 1999 and since 2002 is XFS accessible in the mainline Linux Kernel~\cite[Chap. 1.2, 1.3]{xfsHistory}.

XFS as a whole is separated into three main projects: First, there is the XFS filesystem itself, in the form of a kernel module. Then a set of tools in a package called xfsprogs is tightly connected with XFS filesystem and contains programs useful or necessary for creation and manipulation of the filesystem. Among the tools included are {\tt mkfs.xfs}, on which this thesis is focused, but also other tools: {\tt fsck.xfs}, {\tt xfs\_io}, {\tt xfs\_growfs}, et cetera. And finally, there are xfstests, which is a test suite containing hundreds of shell scripts that verifying the behaviour of entire XFS chain (from mkfs to the kernel code). This project is also partially used by other filesystems. There are among others tests for ext4, overlay fs and btrfs.

Except for the xfstests test suite, xfsprogs also uses an automatical static analysis from Coverity~\cite{CoverityXfsprogs}. However, to see detailed information and defects there, one must be approved by existing members of the project.


\section{Architecture overview}\label{chap:xfs:overview}

When a XFS partition is formated, up to three areas are created on the disk: Data section is always present. An optional real-time section is omitted by default. Log section has to exist always but can be placed on a different device. The data part is then in fact split into multiple de facto independent filesystems called Allocation Groups, that handle space allocation and allows for higher parallelism, as most operations can be done on each Allocation Group independently on the others. The log section can be also internal to each of the Allocation Groups.

As each Allocation Group is a de facto standalone filesystem, each contains the superblock and block and inode allocations.

Real-time section is dedicated for files with a real-time attribute bit set, and operations with these files should have predictable latencies~\cite{xfsRealtime}. Log section is used to recover from situations like power failure on the next mount~\cite{xfsStructure,xfsman}.


\section{mkfs.xfs}\label{chap:xfs:mkfs}
Now I describe in a greater detail the mkfs.xfs program itself, located in file {\tt mkfs/mkfs\_xfs.c}. This tool creates a new XFS filesystem with given properties. It is, as is usual for core Unix utilities, a non-interactive program which accepts multiple arguments when called and prints out the properties of the newly created filesystem if successful, or prints an error and usage help when an error occurs.

\begin{lstlisting}[frame=none, basicstyle=\footnotesize\ttfamily, language=Bash, numbers=none, numberstyle=\tiny\color{black},caption= {Synopsis of mkfs.xfs utility~\cite{mkfs.xfsMan}.}]
mkfs.xfs [ -b block_size ] [ -d data_section_options ] [ -f ]
         [ -i inode_options ] [ -l log_section_options ] [ -n naming_options ]
         [ -p protofile ] [ -q ] [ -r real-time_section_options ]
         [ -s sector_size ] [ -L label ] [ -N ] [ -K ] device
\end{lstlisting}

An example of such usage is {\tt mkfs.xfs -f /dev/sda1}. This simple example creates a XFS filesystem on device {\tt /dev/sda1} even if an existing filesystem existed there -- thus the {\tt -f} (as force) flag. For the whole description of mkfs.xfs usage it is better to refer to mkfs.xfs manual page. What is important to note here is that parsing the input arguments and computing inner values based on these inputs makes most of the circa 3,500\footnote{Before the merge of the last part of my changes. With these changes, mkfs has over 4,000 lines.} lines of code.

Before my refactoring, the code worked in this way: A big loop iterated over all arguments using the standard {\tt getopt} function from {\tt unistd.h}. This analysed the top-level arguments like {\tt -b} or {\tt -f}. For arguments that have some options, there was a second loop that parsed suboptions. In either way, when there were some values to be set that were in a conflict\footnote{For example {\tt -d agsize=x,agcount=y}: It is possible to either set the count of Allocation Groups and their size is computed, or, if size is given, their number is computed. Stating both at once makes no sense and is not allowed.}, then every case was unique. Some options had a test directly within this assignment for both conflicting options, others simply set up the value and tested the conflict later, after the getopt loop. Yet another options used both of these ways, as the author of each change thought it better or how it was required to achieve a given functionality.

It is easy to see what could go bad in this: When changing one option, it was possible to forget to change the other one. If the test was done after getopt, any other option that would modify such a value\footnote{See {\tt -i size=x/log=y}. In the code, both options modify the same variables and differs only in accepted values. {\tt size} expects a number of bytes while {\tt log} expects a base two logarithm value.} could overwrite a conflicting value without a notice.

Any new option required a careful reading through the existing code and possibly place some checks on multiple places. Thus it was difficult to know when any value is checked and safe for use in further computations.



